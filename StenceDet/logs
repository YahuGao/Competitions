1.    使用weibo的预训练词向量 未匹配的词用'，‘替代，填充用'。’
2. 第一次提交成功，模型f1-score为27.1. f1-score是查准率和查全率的权重
平均(两者各占50%)，值为1时最佳，为0时最差
本地测试发现预测结果主要是1和2
统计样本类别分布，发现三个类别的比例为1：2：2，在评判函数交叉熵损失中
加入了各个类别的权重

3. 加入权重后发现效果仍然非常不理想，改进措施，把最后一层的sigmoid换成
softmax 因为sigmoid适用于二分类，而多分类任务应该用softmax，再次测试发
现在线f1-sore 为35.24

4. 考虑到超参数的设置问题，加入了对学习率和正则化项的参数选择循环，本地
测试效果居然达到了92分，进行在线测试

5. 在线测试经过8小时仍然没有结果，估计时资源被占用，计算太慢，观察训练
精度和验证精度曲线，发现训练精度已经接近于1，但是验证精度仍然在0.5左右
波动

6. 重新审查数据处理过程，考虑到直接在数据预处理阶段对每一句话的长度进行
填充，最终会导致有填充的样本经过LSTM的输出结果最后一个输出是对填充内容
的输出, 严重影响模型的效果.
考虑RNN的特性，尝试不进行序列长度的填充, 发现这样无法进行批处理。
网上搜索解决方案，发现可以使用
torch.nn.utils.rnn.pad_sequence()
torch.nn.utils.rnn.pack_padded_sequence()
torch.nn.utils.rnn.pad_packed_sequence()
三个函数进行处理

7. 考虑到使用的是预训练词向量，所以行上述方法还不能直接使用，先把
填充位置调到sequence前方，这样LSTM输出的最后一个out仍然是有意义的

效果不错训练损失和验证损失都降到了0.5 而且本地测试的准确率和f1-score都
为1
在线训练，发现最终f1-score为46.29, 训练损失最终停留在0.6附近而验证损失
停留在1.06附近，说明模型还是存在严重的过拟合情况
调整正则化参数的迭代顺序，再试一次
-clips = [5, 3, 1, 0.5, 0.3, 0.1]
+clips = [0.1, 0.3, 0.5, 1, 3, 5]

8. 添加了early stop 且f1-score 达到了52.33, 在模型中添加dropout层再试一次

9. 加入Dropout后 f1-score 为 49.66 训练损失为0.6左右 验证损失为1.05左右
引入L2正则化继续尝试, 加入正则化后，训练损失和验证损失均维持在1.09左右，
猜想是正则化系数较大导致的, 尝试较小的正则化系数再试一次

10. weight_decays = [0.1, 0.05, 0.03, 0.01]  训练的到的分数为22.5
训练损失较大，训练精度和验证精度均没有明显变化均为0.4左右

11. 去除优化器的正则化后，在线评估的分数增加到了49，正则化果然有问题

12. 在等待结果的过程中发现，pytorch的cross entropy loss 是对softmax，log
和NLLloss的合并，因此删除网络中的softmax层，并本地测试了一把，没有问题

13. 着手在训练和测试过程中使用变长序列，借助pad_sequence, pack_padded_sequence
和pad_packed_sequence三个函数。
避免了训练过程中的Tensor.size([0])的问题后在测试过程中出现了如下问题
...
[200~labels = model.predict_all(x_test)
File "model.py", line 62, in predict_all
batch_first=True)
File "/usr/local/lib/python3.6/dist-packages/torch/nn/utils/rnn.py", line 233, in pack_padded_sequence
_VF._pack_padded_sequence(input, lengths, batch_first)
RuntimeError: Cannot pack empty tensors.
train finish
...

14. 使用变长序列之后，在线训练得分为53.9
