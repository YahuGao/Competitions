1.    使用weibo的预训练词向量 未匹配的词用'，‘替代，填充用'。’
2. 第一次提交成功，模型f1-score为27.1. f1-score是查准率和查全率的权重
平均(两者各占50%)，值为1时最佳，为0时最差
本地测试发现预测结果主要是1和2
统计样本类别分布，发现三个类别的比例为1：2：2，在评判函数交叉熵损失中
加入了各个类别的权重

3. 加入权重后发现效果仍然非常不理想，改进措施，把最后一层的sigmoid换成
softmax 因为sigmoid适用于二分类，而多分类任务应该用softmax，再次测试发
现在线f1-sore 为35.24

4. 考虑到超参数的设置问题，加入了对学习率和正则化项的参数选择循环，本地
测试效果居然达到了92分，进行在线测试

5. 在线测试经过8小时仍然没有结果，估计时资源被占用，计算太慢，观察训练
精度和验证精度曲线，发现训练精度已经接近于1，但是验证精度仍然在0.5左右
波动

6. 重新审查数据处理过程，考虑到直接在数据预处理阶段对每一句话的长度进行
填充，最终会导致有填充的样本经过LSTM的输出结果最后一个输出是对填充内容
的输出, 严重影响模型的效果.
考虑RNN的特性，尝试不进行序列长度的填充, 发现这样无法进行批处理。
网上搜索解决方案，发现可以使用
torch.nn.utils.rnn.pad_sequence()
torch.nn.utils.rnn.pack_padded_sequence()
torch.nn.utils.rnn.pad_packed_sequence()
三个函数进行处理

7. 考虑到使用的是预训练词向量，所以行上述方法还不能直接使用，先把
填充位置调到sequence前方，这样LSTM输出的最后一个out仍然是有意义的

效果不错训练损失和验证损失都降到了0.5 而且本地测试的准确率和f1-score都
为1
在线训练，发现最终f1-score为46.29, 训练损失最终停留在0.6附近而验证损失
停留在1.06附近，说明模型还是存在严重的过拟合情况
调整正则化参数的迭代顺序，再试一次
-clips = [5, 3, 1, 0.5, 0.3, 0.1]
+clips = [0.1, 0.3, 0.5, 1, 3, 5]

8. 添加了early stop 且f1-score 达到了52.33, 在模型中添加dropout层再试一次
