{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义问题\n",
    "- 有哪些数据可以用？\n",
    "- 想要预测什么？\n",
    "- 是否需要收集更多数据或雇人为数据手动添加标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据为新闻文本，并按照字符级别进行匿名处理。整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐的文本数据。\n",
    "赛题数据由以下几个部分构成：训练集20w条样本，测试集A包括5w条样本，测试集B包括5w条样本。为了预防选手人工标注测试集的情况，我们将比赛数据的文本按照字符级别进行了匿名处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 若文件中存在utf-8不能解码的内容， 使用unicode_escape编码格式\n",
    "df = pd.read_csv('data/train_set.csv', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'text'], dtype='object')\n",
      "   label                                               text\n",
      "0      2  2967 6758 339 2021 1854 3731 4109 3792 4149 15...\n",
      "1     11  4464 486 6352 5619 2465 4802 1452 3137 5778 54...\n",
      "2      3  7346 4068 5074 3747 5681 6093 1777 2226 7354 6...\n"
     ]
    }
   ],
   "source": [
    "# 查看数据\n",
    "print(df.columns)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    200000.000000\n",
      "mean        907.207110\n",
      "std         996.029036\n",
      "min           2.000000\n",
      "25%         374.000000\n",
      "50%         676.000000\n",
      "75%        1131.000000\n",
      "max       57921.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 统计每个句子的长度\n",
    "# 把字符串转成整数列表\n",
    "df['text_len'] = df['text'].apply(lambda x: len(x.split(' ')))\n",
    "print(df['text_len'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试集\n",
    "df_test = pd.read_csv('data/test_a.csv', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    50000.000000\n",
      "mean       909.844960\n",
      "std       1032.313375\n",
      "min         14.000000\n",
      "25%        370.000000\n",
      "50%        676.000000\n",
      "75%       1133.000000\n",
      "max      41861.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#　查看测试集每条文本的长度信息\n",
    "df_test['text_len'] = df_test['text'].apply(lambda x: len(x.split(' ')))\n",
    "print(df_test['text_len'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数据有两列，第一列为标签，第二列为进行匿名处理的文本, 手动添加一列，记录每条文本的长度。一共有20万条文本，最大长度为57921，最短长度为2。每条记录的长度差异较大， 需要对较大的进行截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 11  3  9 10 12  0  7  4  1  6  5  8 13]\n",
      "(200000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 查看新闻类别\n",
    "print(df['label'].unique())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfiElEQVR4nO3df5xddX3n8debhGIUEyAMMSbBsBArAZcoszEVW9FQiIAGtqCBKmkbjUWsurWPLqit4G5acFeyi7vQRVBC/AEBtaT8UDAISosJAwZCCJRRIgkJSfgdUNCE9/5xvqM3w83Mnbl3JpPk/Xw8zuOe+znn+7nfO5nM557zPfd7ZJuIiIg9dnQHIiJiaEhBiIgIIAUhIiKKFISIiABSECIiokhBiIgIIAUhos8kWdIhO7ofEa2WghBDgqTVkjZIek1N7MOSbtuB3dotSTpX0td3dD9i8KUgxFAyHPjkju5ExO4qBSGGkv8B/I2kfeptlPQmSbdIekrSQ5LeX+IHSXpG0h7l+WWSNta0+7qkT5X1P5P0c0mbJT0i6U+381rDJH1G0s/KvndLmlBnvxMk/VTSc5LWSDq3Zturyms/Wfp3l6QxreqHpLeXnM+Wx7fXtFst6Zia57/91C9pYjntNVvSo5KekPTZsm0G8BngA5Kel3RvvX7FrikFIYaSDuA24G+6byinkm4BvgkcAJwGXCzpMNuPAM8Bbym7/yHwvKRDy/M/Am4vOS4C3mP7tcDbgeXb6ctfl9c4HhgJ/AXwyzr7vQCcAewDnACcKemksm02MAqYAIwG/hL4VSv6IWk/4IaSZzRwIXCDpNHbyVPPO4DfB6YDfy/pUNvfA/4BuNr23raP6EO+2MmlIMRQ8/fAX0lq6xY/EVht+2u2t9i+B/g2cErZfjvwTkmvK8+vLc8PovpD2vVJ92XgcEkjbK+3vXI7/fgw8DnbD7lyr+0nu+9k+zbbK2y/bPs+4FvAO8vm31D9sT7E9lbbd9t+rkX9OAF42PbC8vP4FvAg8N7t5KnnPNu/sn1v+fnkj/9uLgUhhhTb9wPXA2d32/QG4G3l1Mszkp4B/hToKgC3A0dTHQ38iOpI451l+XH5g/0C8AGqT+rrJd0g6U3b6coE4Ge99VfS2yT9UNImSc+W3PuXzQuB7wNXSVon6YuS9mxRP14P/KJb7BfAuN76XOPxmvVfAnv3oW3sglIQYij6PPARtv3jtga43fY+Ncvets8s22+nOlV0dFm/AziKqiDc3pXE9vdt/zEwluoT9Ve204c1wMEN9PWbwGJggu1RwD8BKq/1G9vn2Z5MdVroRKrTS63oxzqqIlnrQOCxsv4C8Oqaba+jcZkCeTeVghBDju1O4GrgEzXh64E3SvqQpD3L8p+6xglsPwz8Cvgg8KNyamYD8CeUgiBpjKT3lXP4LwHPA1u3043LgP8maZIq/3E75+dfCzxl+0VJU4HTuzZIepekN0saRjXG8Rtga4v6cWP5eZwuabikDwCTy88JqjGJWeXn1M7vTq01YgMwsWuQPnYf+QePoeoLwG+/k2B7M3AsMIvq0/HjwAXAXjVtbgeetP1ozXMBPy3P9wA+Xdo/RXX08LHtvP6FwCLgZqo/5pcDI+rs9zHgC5I2U41/LKrZ9jqqsYzngFWlP19vRT/KOMKJJc+TwN8CJ9p+orT7O6oji6eB86iOZBp1TXl8UtI9fWgXOznlBjkREQE5QoiIiCIFISIigBSEiIgoUhAiIgJIQYiIiGL4ju5Af83Yf38/MXHiju5GRMRO5e67737CdvepYYA+FITy5ZoO4DHbJ5bJta4GJgKrgffbfrrsew4wh+rLNp+w/f0SPxK4gup67huBT9q2pL2AK4Ejqa6p/oDt1T3153sTJ0JHR6Pdj4gIQFL3KU9+qy+njD5J9eWaLmcDS2xPApaU50iaTPXlocOAGVQzUg4rbS4B5gKTyjKjxOcAT9s+BJhP9YWjiIgYRA0VBEnjqWZXvKwmPBNYUNYXACfVxK+y/VKZlrgTmCppLDDS9p2uvg13Zbc2XbmuBaZLUr/eUURE9EujRwj/i+qr8S/XxMbYXg9QHg8o8XFUE3J1WVti48p69/g2bWxvAZ6lmjZ4G5LmSuqQ1LFp06YGux4REY3otSBIOhHYaPvuBnPW+2TvHuI9tdk2YF9qu912e1tb3TGRiIjop0YGlY8C3ifpeOBVwMhyK74NksbaXl9OB3XdsnAt1RzuXcZTTeK1tqx3j9e2WStpONVdpp7q53uKiIh+6PUIwfY5tsfbnkg1WHyr7Q9SzQE/u+w2G7iurC+mmnZ3r3K3qknAsnJaabOkaWV84IxubbpynVJeI7PuRUQMoma+h3A+sEjSHOBR4FQA2yslLQIeALYAZ9numuv9TH532elNZYFqSt+FkjqpjgxmNdGviIjoh513+uv2dud7CBERfSPpbtvt9bbttN9U3p6JZ9/Qp/1Xn3/CAPUkImLnkrmMIiICSEGIiIgiBSEiIoAUhIiIKFIQIiICSEGIiIgiBSEiIoAUhIiIKFIQIiIC2AW/qTzQ8k3oiNhV5QghIiKAFISIiChSECIiAkhBiIiIIgUhIiKAFISIiCh6LQiSXiVpmaR7Ja2UdF6JnyvpMUnLy3J8TZtzJHVKekjScTXxIyWtKNsuKvdWptx/+eoSXypp4gC814iI6EEjRwgvAe+2fQQwBZghaVrZNt/2lLLcCCBpMtU9kQ8DZgAXSxpW9r8EmAtMKsuMEp8DPG37EGA+cEHT7ywiIvqk14LgyvPl6Z5l6elGzDOBq2y/ZPsRoBOYKmksMNL2na5u5HwlcFJNmwVl/VpgetfRQ0REDI6GxhAkDZO0HNgI3GJ7adn0cUn3SfqqpH1LbBywpqb52hIbV9a7x7dpY3sL8Cwwuu9vJyIi+quhgmB7q+0pwHiqT/uHU53+OZjqNNJ64Etl93qf7N1DvKc225A0V1KHpI5NmzY10vWIiGhQn64ysv0McBsww/aGUiheBr4CTC27rQUm1DQbD6wr8fF14tu0kTQcGAU8Vef1L7Xdbru9ra2tL12PiIheNHKVUZukfcr6COAY4MEyJtDlZOD+sr4YmFWuHDqIavB4me31wGZJ08r4wBnAdTVtZpf1U4BbyzhDREQMkkZmOx0LLChXCu0BLLJ9vaSFkqZQndpZDXwUwPZKSYuAB4AtwFm2t5ZcZwJXACOAm8oCcDmwUFIn1ZHBrObfWkRE9EWvBcH2fcBb6sQ/1EObecC8OvEO4PA68ReBU3vrS0REDJx8UzkiIoAUhIiIKFIQIiICSEGIiIgiBSEiIoAUhIiIKFIQIiICSEGIiIgiBSEiIoAUhIiIKFIQIiICSEGIiIgiBSEiIoAUhIiIKBq5H0IMooln39Cn/Veff8IA9SQidjc5QoiICCAFISIiihSEiIgAGigIkl4laZmkeyWtlHReie8n6RZJD5fHfWvanCOpU9JDko6riR8paUXZdpEklfhekq4u8aWSJg7Ae42IiB40coTwEvBu20cAU4AZkqYBZwNLbE8ClpTnSJoMzAIOA2YAF0saVnJdAswFJpVlRonPAZ62fQgwH7ig+bcWERF90WtBcOX58nTPshiYCSwo8QXASWV9JnCV7ZdsPwJ0AlMljQVG2r7TtoEru7XpynUtML3r6CEiIgZHQ2MIkoZJWg5sBG6xvRQYY3s9QHk8oOw+DlhT03xtiY0r693j27SxvQV4Fhhdpx9zJXVI6ti0aVNDbzAiIhrTUEGwvdX2FGA81af9w3vYvd4ne/cQ76lN935carvddntbW1svvY6IiL7o01VGtp8BbqM697+hnAaiPG4su60FJtQ0Gw+sK/HxdeLbtJE0HBgFPNWXvkVERHMaucqoTdI+ZX0EcAzwILAYmF12mw1cV9YXA7PKlUMHUQ0eLyunlTZLmlbGB87o1qYr1ynArWWcISIiBkkjU1eMBRaUK4X2ABbZvl7SncAiSXOAR4FTAWyvlLQIeADYApxle2vJdSZwBTACuKksAJcDCyV1Uh0ZzGrFm4uIiMb1WhBs3we8pU78SWD6dtrMA+bViXcArxh/sP0ipaBERMSOkW8qR0QEkIIQERFFCkJERAApCBERUaQgREQEkIIQERFFCkJERAApCBERUaQgREQEkIIQERFFCkJERAApCBERUaQgREQEkIIQERFFCkJERAApCBERUaQgREQEkIIQERFFrwVB0gRJP5S0StJKSZ8s8XMlPSZpeVmOr2lzjqROSQ9JOq4mfqSkFWXbRZJU4ntJurrEl0qaOADvNSIietDIEcIW4NO2DwWmAWdJmly2zbc9pSw3ApRts4DDgBnAxZKGlf0vAeYCk8oyo8TnAE/bPgSYD1zQ/FuLiIi+6LUg2F5v+56yvhlYBYzroclM4CrbL9l+BOgEpkoaC4y0fadtA1cCJ9W0WVDWrwWmdx09RETE4OjTGEI5lfMWYGkJfVzSfZK+KmnfEhsHrKlptrbExpX17vFt2tjeAjwLjK7z+nMldUjq2LRpU1+6HhERvWi4IEjaG/g28Cnbz1Gd/jkYmAKsB77UtWud5u4h3lObbQP2pbbbbbe3tbU12vWIiGhAQwVB0p5UxeAbtr8DYHuD7a22Xwa+Akwtu68FJtQ0Hw+sK/HxdeLbtJE0HBgFPNWfNxQREf3TyFVGAi4HVtm+sCY+tma3k4H7y/piYFa5cuggqsHjZbbXA5slTSs5zwCuq2kzu6yfAtxaxhkiImKQDG9gn6OADwErJC0vsc8Ap0maQnVqZzXwUQDbKyUtAh6gukLpLNtbS7szgSuAEcBNZYGq4CyU1El1ZDCrmTcVERF912tBsH0H9c/x39hDm3nAvDrxDuDwOvEXgVN760tERAycfFM5IiKAFISIiChSECIiAkhBiIiIIgUhIiKAFISIiChSECIiAkhBiIiIIgUhIiKAxqauiF3IxLNv6NP+q88/YYB6EhFDTY4QIiICSEGIiIgiBSEiIoAUhIiIKFIQIiICSEGIiIgiBSEiIoDG7qk8QdIPJa2StFLSJ0t8P0m3SHq4PO5b0+YcSZ2SHpJ0XE38SEkryraLyr2VKfdfvrrEl0qaOADvNSIietDIEcIW4NO2DwWmAWdJmgycDSyxPQlYUp5Tts0CDgNmABdLGlZyXQLMBSaVZUaJzwGetn0IMB+4oAXvLSIi+qDXgmB7ve17yvpmYBUwDpgJLCi7LQBOKuszgatsv2T7EaATmCppLDDS9p22DVzZrU1XrmuB6V1HDxERMTj6NIZQTuW8BVgKjLG9HqqiARxQdhsHrKlptrbExpX17vFt2tjeAjwLjO5L3yIiojkNFwRJewPfBj5l+7medq0Tcw/xntp078NcSR2SOjZt2tRblyMiog8aKgiS9qQqBt+w/Z0S3lBOA1EeN5b4WmBCTfPxwLoSH18nvk0bScOBUcBT3fth+1Lb7bbb29raGul6REQ0qJGrjARcDqyyfWHNpsXA7LI+G7iuJj6rXDl0ENXg8bJyWmmzpGkl5xnd2nTlOgW4tYwzRETEIGlk+uujgA8BKyQtL7HPAOcDiyTNAR4FTgWwvVLSIuABqiuUzrK9tbQ7E7gCGAHcVBaoCs5CSZ1URwazmntbERHRV70WBNt3UP8cP8D07bSZB8yrE+8ADq8Tf5FSUCIiYsfIN5UjIgJIQYiIiCIFISIigBSEiIgoUhAiIgJIQYiIiCIFISIigBSEiIgoUhAiIgJIQYiIiCIFISIigBSEiIgoUhAiIgJIQYiIiCIFISIigBSEiIgoUhAiIgJIQYiIiKLXgiDpq5I2Srq/JnaupMckLS/L8TXbzpHUKekhScfVxI+UtKJsu0iSSnwvSVeX+FJJE1v8HiMiogGNHCFcAcyoE59ve0pZbgSQNBmYBRxW2lwsaVjZ/xJgLjCpLF055wBP2z4EmA9c0M/3EhERTei1INj+EfBUg/lmAlfZfsn2I0AnMFXSWGCk7TttG7gSOKmmzYKyfi0wvevoISIiBs/wJtp+XNIZQAfwadtPA+OAn9Tss7bEflPWu8cpj2sAbG+R9CwwGnii+wtKmkt1lMHGAw+krYnOx8CYePYNfdp/9fknDFBPIqKv+juofAlwMDAFWA98qcTrfbJ3D/Ge2rwyaF9qu912e1tbykFERCv1qyDY3mB7q+2Xga8AU8umtcCEml3HA+tKfHyd+DZtJA0HRtH4KaqIiGiRfhWEMibQ5WSg6wqkxcCscuXQQVSDx8tsrwc2S5pWxgfOAK6raTO7rJ8C3FrGGSIiYhD1OoYg6VvA0cD+ktYCnweOljSF6tTOauCjALZXSloEPABsAc6yvbWkOpPqiqURwE1lAbgcWCipk+rIYFYL3ldERPRRrwXB9ml1wpf3sP88YF6deAdweJ34i8CpvfUjIiIGVr6pHBERQApCREQUKQgREQGkIERERJGCEBERQApCREQUKQgREQGkIERERJGCEBERQHPTX0cMukyvHTFwcoQQERFACkJERBQpCBERAaQgREREkYIQERFACkJERBQpCBERATRQECR9VdJGSffXxPaTdIukh8vjvjXbzpHUKekhScfVxI+UtKJsu6jcW5ly/+WrS3yppIktfo8REdGARo4QrgBmdIudDSyxPQlYUp4jaTLVPZEPK20uljSstLkEmAtMKktXzjnA07YPAeYDF/T3zURERP/1WhBs/wh4qlt4JrCgrC8ATqqJX2X7JduPAJ3AVEljgZG277Rt4MpubbpyXQtM7zp6iIiIwdPfMYQxttcDlMcDSnwcsKZmv7UlNq6sd49v08b2FuBZYHQ/+xUREf3U6rmM6n2ydw/xntq8Mrk0l+q0ExsPPJC2/vQwogd9mSsp8yTFrqa/RwgbymkgyuPGEl8LTKjZbzywrsTH14lv00bScGAUrzxFBYDtS223225va0s5iIhopf4WhMXA7LI+G7iuJj6rXDl0ENXg8bJyWmmzpGllfOCMbm26cp0C3FrGGSIiYhD1espI0reAo4H9Ja0FPg+cDyySNAd4FDgVwPZKSYuAB4AtwFm2t5ZUZ1JdsTQCuKksAJcDCyV1Uh0ZzGrJO4uIiD7ptSDYPm07m6ZvZ/95wLw68Q7g8DrxFykFJSIidpx8UzkiIoDcMS1i0ORubzHU5QghIiKAFISIiChSECIiAkhBiIiIIoPKEbuIDFpHs3KEEBERQApCREQUKQgREQGkIERERJGCEBERQApCREQUKQgREQGkIERERJGCEBERQApCREQUmboiIhqSqTF2fU0dIUhaLWmFpOWSOkpsP0m3SHq4PO5bs/85kjolPSTpuJr4kSVPp6SLJKmZfkVERN+14pTRu2xPsd1enp8NLLE9CVhSniNpMjALOAyYAVwsaVhpcwkwF5hUlhkt6FdERPTBQIwhzAQWlPUFwEk18atsv2T7EaATmCppLDDS9p22DVxZ0yYiIgZJswXBwM2S7pY0t8TG2F4PUB4PKPFxwJqatmtLbFxZ7x5/BUlzJXVI6ti0aVOTXY+IiFrNDiofZXudpAOAWyQ92MO+9cYF3EP8lUH7UuBSANrb6+4TETunDFrveE0dIdheVx43At8FpgIbymkgyuPGsvtaYEJN8/HAuhIfXyceERGDqN8FQdJrJL22ax04FrgfWAzMLrvNBq4r64uBWZL2knQQ1eDxsnJaabOkaeXqojNq2kRExCBp5pTRGOC75QrR4cA3bX9P0l3AIklzgEeBUwFsr5S0CHgA2AKcZXtryXUmcAUwAripLBERMYj6XRBs/xw4ok78SWD6dtrMA+bViXcAh/e3LxER0bxMXREREUAKQkREFCkIEREBpCBERESR2U4jYreQL771LkcIEREBpCBERESRghAREUAKQkREFCkIEREBpCBERESRy04jIlpgV7isNUcIEREBpCBERESRghAREUAKQkREFBlUjojYCQzGoHWOECIiAhhCBUHSDEkPSeqUdPaO7k9ExO5mSBQEScOA/wu8B5gMnCZp8o7tVUTE7mVIFARgKtBp++e2fw1cBczcwX2KiNityPaO7gOSTgFm2P5wef4h4G22P95tv7nAXIBfwu+PgIcafY3HYf/XwRMt7HbyJ/+Qz538yd/dT+AN0+y2etuGSkE4FTiuW0GYavuvWvgaHbbbW5Uv+ZN/Z8id/MnfF0PllNFaYELN8/HAuh3Ul4iI3dJQKQh3AZMkHSTp94BZwOId3KeIiN3KkPhimu0tkj4OfB8YBnzV9soWv8ylLc6X/Mm/M+RO/uRv2JAYQ4iIiB1vqJwyioiIHSwFISIigBSEiIgohsSg8kCQ9CaqbzuPA0x1Geti26t2aMcaVPo/Dlhq+/ma+Azb32tB/qmAbd9VpgmZATxo+8Zmc9d5rSttn9HqvCX3O6i+6X6/7ZtbkO9twCrbz0kaAZwNvBV4APgH2882mf8TwHdtr2m2r9vJ33WV3jrbP5B0OvB2YBVwqe3ftOA1DgZOprpUfAvwMPCtZn82sePtkoPKkv4rcBrVFBhrS3g81X+Uq2yfP4Cv/ee2v9Zkjk8AZ1H9J54CfNL2dWXbPbbf2mT+z1PNGzUcuAV4G3AbcAzwfdvzmsjd/XJhAe8CbgWw/b7+5i75l9meWtY/QvVz+i5wLPAvzf7bSloJHFGufLsU+CVwLTC9xP9zk/mfBV4AfgZ8C7jG9qZmcnbL/w2qf9dXA88AewPfoeq/bM9uMv8ngPcCtwPHA8uBp6kKxMds39ZM/tjBbO9yC/DvwJ514r8HPDzAr/1oC3KsAPYu6xOBDqqiAPDTFuUfRvVH4zlgZImPAO5rMvc9wNeBo4F3lsf1Zf2dLej7T2vW7wLayvprgBUtyL+q9r1027a8Ff2nOlV7LHA5sAn4HjAbeG0L8t9XHocDG4Bh5bma/bet/d0p668GbivrB7bod3MUcD7wIPBkWVaV2D7N5u/ltW9qQY6RwD8CC4HTu227uAX5XwdcQjUZ6Gjg3PJvsggY22z+XXUM4WXg9XXiY8u2pki6bzvLCmBMs/mp/sM9D2B7NdUf1fdIupDqP3azttjeavuXwM9sP1de61c0//NpB+4GPgs86+oT469s32779iZzA+whaV9Jo6k+8W4CsP0C1emLZt0v6c/L+r2S2gEkvRFo+nQL1Wm6l23fbHsO1e/pxVSn7H7egvx7lNNGr6X6gz2qxPcC9mxBfvjdqea9yutg+9EW5V9EdcRxtO3RtkdTHWE+DVzTbHJJb93OciTV0Xizvkb1f/TbwCxJ35a0V9k2rQX5r6A6fbkG+CHwK+AE4MfAPzWbfFcdQ/gUsETSw1Q/OKg+wRwCfHx7jfpgDHAc1S9pLQH/1oL8j0uaYns5gO3nJZ0IfBV4cwvy/1rSq0tBOLIrKGkUTRYE2y8D8yVdUx430Nrfs1FUBUeAJb3O9uOS9qY1xfLDwP+W9DmqCcPulLSG6vfowy3Iv00fXZ3TXwwsLmMWzbqc6tP1MKqifI2kn1P9MbqqBfkvA+6S9BPgj4ALACS1AU+1IP9E2xfUBmw/Dlwg6S9akP8uqtNd9X5X9mlB/oNt/0lZ/2dJnwVuldTUqdIaY2x/GUDSx2p+Vl+WNKfZ5LvkGAKApD2oBhvHUf3jrwXusr21BbkvB75m+446275p+/Qm84+n+hT/eJ1tR9n+1ybz72X7pTrx/akOO1c0k79bzhOAo2x/plU5t/M6r6b6z/JIi/K9FvgPVMVsre0NLcr7Rtv/3opcPbzG6wFsr5O0D9XY0KO2l7Uo/2HAoVQD+Q+2ImdN7puBHwALun7mksYAfwb8se1jmsx/P3Cy7YfrbFtje0KdZn3Jvwo4rHww6orNBv6W6jTwG5rMf6/tI8r6f7f9uZptK2w39YFxly0IEbHzkbQv1ZVdM4EDSngD1VHU+ba7H5X3Nf8pVGNNr5g6X9JJtv+5yfxfBG62/YNu8RnAl21PajL/F4AvuubKwxI/hOrnc0pT+VMQImJn0Ior+JK/lxwpCBGxM5D0qO0Dk3/g8u+qg8oRsROSdN/2NtGCK/iSv2cpCBExlAz0FXzJ34MUhIgYSq6nuhpnefcNkm5L/oHNnzGEiIgAMttpREQUKQgREQGkIEQ0TNLRkt6+o/sRMVBSECIadzTVvQUGjCr5fxk7RH7xYrcn6YwyW+29khZKeq+kpZJ+KukHksZImgj8JfBfJC2X9IeS2spslneV5aiSr03SLZLukfT/JP2izBOFpL+WdH9ZPlViEyWtknQx1fThfydpfk3/PlJmuo0YULnKKHZrZaK271BNwPeEpP2o7rD3jG1L+jBwqO1PSzoXeN72/yxtv0k1x/0dkg6kurnQoZL+D/CY7X8sc9jcBLQBb6Cavnga1XXjS4EPUl1T/nPg7bZ/Iuk1wH3Am2z/RtK/AR9t5aSDEfXkewixu3s3cK3tJwBsPyXpzcDVksZS3VRpezOoHgNMln47k/LIMkvqO6juIIbt70nq+hLRO6hun/kCgKTvAH9INXHbL2z/pLR5QdKtwIll9sw9UwxiMKQgxO5OVEcEtb4MXGh7saSjqe5KVc8ewB+UGwv9LmFNhajzWtvzQrfnlwGfobq3wYBNiBZRK2MIsbtbArxf1R3YKKeMRgGPle219yDeTLlDWHEzNTdckjSlrN4BvL/EjgX2LfEfASdJenU5LXQy1Z2uXsH2Uqqb2J9Ode/liAGXghC7NdsrgXnA7ZLuBS6kOiK4RtKPqe6a1uVfgJO7BpWBTwDtZUD6AapBZ4DzgGMl3QO8h+qe0ptt30M1hrCMavzgMts/7aF7i4B/bfYeABGNyqByRIupuofuVttbJP0BcIntKf3Icz0w3/aSVvcxop6MIUS03oHAovJ9gl8DH+lL43Lby2XAvSkGMZhyhBAREUDGECIiokhBiIgIIAUhIiKKFISIiABSECIiokhBiIgIAP4/hKGoo1ul5OsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 一共有14个类别，查看各个类别分布\n",
    "import matplotlib.pyplot as plt\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "ax = plt.gca() # 获取当前的axes\n",
    "ax.spines['left'].set_color('red')\n",
    "ax.spines['bottom'].set_color('red')\n",
    "plt.title('News class count')\n",
    "plt.xlabel('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    199995.000000\n",
      "mean        907.229601\n",
      "std         996.031330\n",
      "min          11.000000\n",
      "25%         374.000000\n",
      "50%         676.000000\n",
      "75%        1131.000000\n",
      "max       57921.000000\n",
      "Name: text_len, dtype: float64\n",
      "(199995, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 尝试删除长度过小的文本，测试集中长度最小的文本为14, 只有0.25的文本长度小于370\n",
    "# 查看长度小于10的文本的类别分布情况\n",
    "tmp = df.loc[df['text_len']>10]\n",
    "print(tmp['text_len'].describe())\n",
    "print(tmp.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "tmp['label'].value_counts().plot(kind='bar')\n",
    "ax = plt.gca() # 获取当前的axes\n",
    "ax.spines['left'].set_color('red')\n",
    "ax.spines['bottom'].set_color('red')\n",
    "plt.title('News class count')\n",
    "plt.xlabel('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各个类别分布严重不平衡, 且删除长度小于10的文本后，各类别分布基本不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用长度小于10的文本，作为训练集\n",
    "df = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个字符出现的次数\n",
    "# 执行时 kernel will restart\n",
    "if False:\n",
    "    from collections import Counter\n",
    "    all_lines = ' '.join(list(df['text']))\n",
    "    word_count = Counter(all_lines.split(\" \"))\n",
    "    word_count = sorted(word_count.items(), key=lambda d:d[1], reverse=True)\n",
    "    # 一共有多少个字\n",
    "    print(len(word_count))\n",
    "    # 出现次数最多的字的编号\n",
    "    print(word_count[0])\n",
    "    # 出现次数最少的字的编号\n",
    "    print(word_count[-1])\n",
    "# 根据不同字符在句子中出现的次数， 推测标点符号\n",
    "# 根据推测的标点符号， 分析每篇新闻由多少个句子组成\n",
    "# 分析每类新闻中 出现次数最多的字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练集中最大的字的编号\n",
    "df['max'] = df['text'].apply(lambda x: max([int(num) for num in x.split()]))\n",
    "df['max'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练集中最小的字的编号\n",
    "df['max'] = df['text'].apply(lambda x: min([int(num) for num in x.split()]))\n",
    "df['max'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析的结论\n",
    "1. 每个新闻平均字符个数较多，可能需要截断\n",
    "2. 各个类别不均衡， 会严重影响模型的精度\n",
    "3. 训练集中最大的编号为7549， 假设共有10000个不同的编号，即max_features=10000\n",
    "4. 设置文本的长度为最大长度为300， maxlen=300\n",
    "5. 最小编号为0， padding之前应对所有字符+1 或指定padding的value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 评估目标的方法\n",
    "- 使用哪种指标对目标进行评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目共存在14个类别， 且类别分布严重不平衡， 所以采用f1-score作为评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 准备用于评估模型的验证过程。\n",
    "- 定义训练集、验证集和测试集。验证集和测试集应该和训练集分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train = df['text'].values.tolist()\n",
    "y_train = df['label'].values.tolist()\n",
    "x_test = df_test['text'].values.tolist()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=0.3,\n",
    "                                                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义keras的数据生成器\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x, y, n_classes, maxlen=400, batch_size=32):\n",
    "        '''Initialization'''\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_classes = n_classes\n",
    "        self.maxlen = maxlen\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        ''' Denotes the number of batches per epoch'''\n",
    "        # 必须进行整型转换\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "    \n",
    "    def __data_process(self, inputs):\n",
    "        '''Generate data containing batch_size samples'''\n",
    "        X = []\n",
    "        for x in inputs:\n",
    "            # 将字符串转成整数的列表\n",
    "            sentence = [int(num)+1 for num in x.split()]\n",
    "            X.append(sentence)\n",
    "        return X\n",
    "    \n",
    "    #一个batch的数据处理，返回需要feed到模型中训练的数据\n",
    "    def __getitem__(self, index):\n",
    "        '''Generate one batch of data'''\n",
    "        # Generate indexes of the batch\n",
    "        indexes = range(index*self.batch_size, (index+1)*self.batch_size)\n",
    "        \n",
    "        # Get inputs and labels from original data\n",
    "        x = [self.x[index] for index in indexes]\n",
    "        y = [self.y[index] for index in indexes]\n",
    "        \n",
    "        # Process inputs if needed\n",
    "        x = self.__data_process(x)\n",
    "        \n",
    "        # padding\n",
    "        x = sequence.pad_sequences(x, self.maxlen)\n",
    "        \n",
    "        # Transfer type to numpy.ndarray\n",
    "        x = np.array(x)\n",
    "        y = keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 定义一个序列的最大长度\n",
    "maxlen = 400\n",
    "n_classes = 14\n",
    "# 定义最大的字的编号（特征数）\n",
    "max_features = 8000\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "\n",
    "train_generator = DataGenerator(x_train, y_train,\n",
    "                                n_classes,\n",
    "                                batch_size=batch_size,\n",
    "                                maxlen=maxlen,\n",
    "                               )\n",
    "val_generator = DataGenerator(x_val, y_val,\n",
    "                              n_classes,\n",
    "                              batch_size=batch_size,\n",
    "                              maxlen=maxlen,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据向量化（数据预处理）\n",
    "- 将数据转换为能被神经网络接收的形式 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\\n\\ncheckpoint=ModelCheckpoint(filepath, monitor='val_f1_score', save_best_only=True, save_weights_only=True, mode='max')\\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\\nscores = model.evaluate(test_data, test_labels, verbose=0)\\nprint('F1-score: ', scores[1])\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义keras中计算f1-score的方法\n",
    "# Copy from: https://www.fomalhaut.cn/370\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def create_f1():\n",
    "    def f1_function(y_true, y_pred):\n",
    "        y_pred_binary = tf.where(y_pred>=0.5, 1., 0.)\n",
    "        # Avoid TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.\n",
    "        tp = tf.reduce_sum(y_true * y_pred_binary)\n",
    "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "        predicted_positives = tf.reduce_sum(y_pred_binary)\n",
    "        possible_positives = tf.reduce_sum(y_true)\n",
    "        return tp, predicted_positives, possible_positives\n",
    "    return f1_function\n",
    "class F1_score(keras.metrics.Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.f1_function = create_f1()\n",
    "        self.tp_count = self.add_weight(\"tp_count\", initializer=\"zeros\")\n",
    "        self.all_predicted_positives = self.add_weight('all_predicted_positives', initializer='zeros')\n",
    "        self.all_possible_positives = self.add_weight('all_possible_positives', initializer='zeros')\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        tp, predicted_positives, possible_positives = self.f1_function(y_true, y_pred)\n",
    "        self.tp_count.assign_add(tp)\n",
    "        self.all_predicted_positives.assign_add(predicted_positives)\n",
    "        self.all_possible_positives.assign_add(possible_positives)\n",
    "    def result(self):\n",
    "        precision = self.tp_count / self.all_predicted_positives\n",
    "        recall = self.tp_count / self.all_possible_positives\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        return f1\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer= \"adam\", metrics=[F1_score()]) # NOTE： F1_score()\n",
    "# 这种写法最大的优点在于，相当于在原来acc，loss的基础上添加了一个新的monitor即’val_f1_score’。\n",
    "# checkpoint和earlystoping都可以使用这个参数来决定早停和保存模型, 测试集评估模型的时候，也能直接调用而不需要修改代码。例如：\n",
    "'''\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_f1_score', save_best_only=True, save_weights_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "scores = model.evaluate(test_data, test_labels, verbose=0)\n",
    "print('F1-score: ', scores[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必须的包\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding, SimpleRNN\n",
    "\n",
    "# 定义一个简单的RNN模型\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 100))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=[F1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_f1_score',\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='SimpleRNN.h5',\n",
    "        monitor='val_f1_score',\n",
    "        save_best_only=True,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15192635899364302272\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14263522586555768966\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10630974656\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14737619137310654664\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13903501323727520354\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 查看有效的CPU和GPU\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"99\"\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定使用GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"             #选用GPU序号\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "136/136 [==============================] - 43s 313ms/step - loss: 0.8963 - f1_score: 0.7274 - val_loss: 0.8408 - val_f1_score: 0.7446\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 42s 311ms/step - loss: 0.8512 - f1_score: 0.7405 - val_loss: 0.8948 - val_f1_score: 0.7379\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 42s 311ms/step - loss: 0.8511 - f1_score: 0.7422 - val_loss: 1.0059 - val_f1_score: 0.7184\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 43s 314ms/step - loss: 0.9191 - f1_score: 0.7209 - val_loss: 0.9104 - val_f1_score: 0.7175\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 42s 311ms/step - loss: 0.8330 - f1_score: 0.7505 - val_loss: 0.8522 - val_f1_score: 0.7486\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 43s 313ms/step - loss: 0.8103 - f1_score: 0.7571 - val_loss: 0.8494 - val_f1_score: 0.7444\n"
     ]
    }
   ],
   "source": [
    "# 拟合模型\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_freq=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 开发模型\n",
    "- 使用fasttext模型作为基线模型， fasttext在划分的验证集上的f1score为0.8972\n",
    "- 简单的RNN模型验证的f1-score为0.744远小于 fasttext，\n",
    "- 尝试使用biLSTM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 调节超参数和正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用一个biLSTM提取特征\n",
    "# 导入必须的包\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding, Bidirectional, LSTM\n",
    "\n",
    "# 定义一个简单的双向RNN模型\n",
    "class biLSTM():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(max_features, 100))\n",
    "        # model.add(SimpleRNN(32))\n",
    "        model.add(Bidirectional(LSTM(128)))\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                      metrics=[F1_score()])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "136/136 [==============================] - 47s 342ms/step - loss: 1.6386 - f1_score: 0.3955 - val_loss: 1.0554 - val_f1_score: 0.6480\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 47s 344ms/step - loss: 0.9364 - f1_score: 0.6972 - val_loss: 0.7270 - val_f1_score: 0.7739\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 46s 335ms/step - loss: 0.7294 - f1_score: 0.7754 - val_loss: 0.6977 - val_f1_score: 0.7820\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 45s 334ms/step - loss: 0.6443 - f1_score: 0.8049 - val_loss: 0.5548 - val_f1_score: 0.8367\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 46s 337ms/step - loss: 0.5809 - f1_score: 0.8286 - val_loss: 0.6085 - val_f1_score: 0.8244\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 46s 337ms/step - loss: 0.5600 - f1_score: 0.8345 - val_loss: 0.6959 - val_f1_score: 0.7860\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_f1_score',\n",
    "        patience=2,\n",
    "        mode='max'\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='biLSTM.h5',\n",
    "        monitor='val_f1_score',\n",
    "        save_best_only=True,\n",
    "    )]\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_freq=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双向LSTM模型在训练到第4轮时达到最佳f1-score： 0.8367，相比于简单的RNN有了较大的提升， 但仍远小于fasttext的效果。\n",
    "从之前类别分布的信息中，我们知道， 样本的类别分布是非常不平衡的， 但是对于每个类别， 我们是同等对待的。 因此这里引入样本权重，来解决样本分布不均衡的问题。\n",
    "在生成器中， 我们没有加入样本的权重， 下面可以尝试添加样本的权重再次训练该网络。为了避免将验证集的信息引入模型的训练过程， 在计算类别权重时，应该使用划分好的训练数据。\n",
    "本问题中，各个类别之间应该是同等重要的，因此，不指定类别权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义keras的附带权重信息的数据生成器\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x, y=None, n_classes=None, maxlen=400, batch_size=32):\n",
    "        '''Initialization'''\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_classes = n_classes\n",
    "        self.maxlen = maxlen\n",
    "        self.batch_size = batch_size\n",
    "        if self.y:\n",
    "            self.sample_weights = compute_sample_weight(\"balanced\", self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        ''' Denotes the number of batches per epoch'''\n",
    "        # 必须进行整型转换\n",
    "        return int(np.floor(len(self.x) / self.batch_size))\n",
    "    \n",
    "    def __data_process(self, inputs):\n",
    "        '''Generate data containing batch_size samples'''\n",
    "        X = []\n",
    "        for x in inputs:\n",
    "            # 将字符串转成整数的列表\n",
    "            sentence = [int(num)+1 for num in x.split()]\n",
    "            X.append(sentence)\n",
    "        return X\n",
    "    \n",
    "    #一个batch的数据处理，返回需要feed到模型中训练的数据\n",
    "    def __getitem__(self, index):\n",
    "        '''Generate one batch of data'''\n",
    "        # Generate indexes of the batch\n",
    "        indexes = range(index*self.batch_size, (index+1)*self.batch_size)\n",
    "        \n",
    "        # Get inputs and labels from original data\n",
    "        x = [self.x[index] for index in indexes]\n",
    "        \n",
    "        # Process inputs if needed\n",
    "        x = self.__data_process(x)\n",
    "        \n",
    "        # padding\n",
    "        x = sequence.pad_sequences(x, self.maxlen)\n",
    "        \n",
    "        # Transfer type to numpy.ndarray\n",
    "        x = np.array(x)\n",
    "\n",
    "        if self.y:\n",
    "            y = [self.y[index] for index in indexes]\n",
    "            sample_weights = [self.sample_weights[index] for index in indexes]\n",
    "            y = keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "            sample_weights = np.array(sample_weights)\n",
    "        \n",
    "            return x, y, sample_weights\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 定义一个序列的最大长度\n",
    "maxlen = 400\n",
    "n_classes = 14\n",
    "# 定义最大的字的编号（特征数）\n",
    "max_features = 8000\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "embedding_dims = 128\n",
    "\n",
    "train_generator = DataGenerator(x_train, y_train,\n",
    "                                n_classes,\n",
    "                                batch_size=batch_size,\n",
    "                                maxlen=maxlen,\n",
    "                               )\n",
    "val_generator = DataGenerator(x_val, y_val,\n",
    "                              n_classes,\n",
    "                              batch_size=batch_size,\n",
    "                              maxlen=maxlen,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_f1_score_1',\n",
    "        patience=2,\n",
    "        mode='max'\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='biLSTM_sample_weights.h5',\n",
    "        monitor='val_f1_score_1',\n",
    "        save_best_only=True,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'biLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-53cb34c562cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'biLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "model = biLSTM().get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "136/136 [==============================] - 47s 343ms/step - loss: 1.9784 - f1_score: 0.0907 - val_loss: 1.3752 - val_f1_score: 0.2964\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 47s 344ms/step - loss: 1.1171 - f1_score: 0.4765 - val_loss: 0.9579 - val_f1_score: 0.6224\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 47s 348ms/step - loss: 0.7824 - f1_score: 0.6923 - val_loss: 0.8791 - val_f1_score: 0.5191\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 47s 349ms/step - loss: 0.6701 - f1_score: 0.7436 - val_loss: 0.6427 - val_f1_score: 0.7707\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 47s 345ms/step - loss: 0.5835 - f1_score: 0.7892 - val_loss: 0.6056 - val_f1_score: 0.8107\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 46s 341ms/step - loss: 0.5343 - f1_score: 0.8081 - val_loss: 0.5781 - val_f1_score: 0.8394\n",
      "Epoch 7/10\n",
      "136/136 [==============================] - 46s 341ms/step - loss: 0.4980 - f1_score: 0.8199 - val_loss: 0.6101 - val_f1_score: 0.8001\n",
      "Epoch 8/10\n",
      "136/136 [==============================] - 47s 346ms/step - loss: 0.4587 - f1_score: 0.8362 - val_loss: 0.5225 - val_f1_score: 0.8311\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_freq=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入样本权重后， 模型泛化效果并没有想象中的得到提升，f1-score仅有0.8394， 下面定义一个卷积网络进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "class TextCNN():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "        model.add(Conv1D(32, 7, activation='relu'))\n",
    "        model.add(MaxPooling1D(5))\n",
    "        model.add(Conv1D(32, 7, activation='relu'))\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "model = TextCNN().get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[F1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_freq=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 8/10  \n",
    "136/136 [==============================] - ETA: 0s - loss: 0.2736 - f1_score_1: 0.8938WARNING:tensorflow:Early   stopping conditioned on metric `val_f1_score` which is not available. Available metrics are:   loss,f1_score_1,val_loss,val_f1_score_1  \n",
    "WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.  \n",
    "136/136 [==============================] - 43s 313ms/step - loss: 0.2736 - f1_score_1: 0.8938 - val_loss: 0.4793 - val_f1_score_1: 0.8729  \n",
    "同一个notebook中第二次拟合模型时， monitor metrics 会由定义的val_f1_score变成val_f1_score_1  \n",
    "TextCNN在训练到第8轮时达到最优， 然后开始过拟合， f1-score为0.8729， 相比biLSTM有了些许提升， 相比fasttext的0.89已非常接近。  \n",
    "尝试结合RNN和CNN进行训练  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, Lambda, Concatenate, Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "class TextRCNN(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_model(self):\n",
    "        input_text = Input((maxlen,))\n",
    "\n",
    "        embedder = Embedding(max_features, embedding_dims, input_length=maxlen)\n",
    "        embedding = embedder(input_text)\n",
    "\n",
    "        x_left = SimpleRNN(128, return_sequences=True)(embedding)\n",
    "        x_right = SimpleRNN(128, return_sequences=True, go_backwards=True)(embedding)\n",
    "        x_right = Lambda(lambda x: K.reverse(x, axes=1))(x_right)\n",
    "        x = Concatenate(axis=2)([x_left, embedding, x_right])\n",
    "\n",
    "        x = Conv1D(64, kernel_size=1, activation='tanh')(x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "        output = Dense(n_classes, activation='softmax')(x)\n",
    "        model = Model(inputs=input_text, outputs=output)\n",
    "        return model\n",
    "    \n",
    "textRCNN = TextRCNN().get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "textRCNN.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[F1_score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_f1_score_1',\n",
    "        patience=2,\n",
    "        mode='max'\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='RCNN.h5',\n",
    "        monitor='val_f1_score_1',\n",
    "        save_best_only=True,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "136/136 [==============================] - 64s 474ms/step - loss: 1.9876 - f1_score_1: 0.1239 - val_loss: 1.1239 - val_f1_score_1: 0.5058\n",
      "Epoch 2/100\n",
      "136/136 [==============================] - 64s 471ms/step - loss: 0.7806 - f1_score_1: 0.7100 - val_loss: 0.5565 - val_f1_score_1: 0.8279\n",
      "Epoch 3/100\n",
      "136/136 [==============================] - 64s 471ms/step - loss: 0.4472 - f1_score_1: 0.8436 - val_loss: 0.5350 - val_f1_score_1: 0.7872\n",
      "Epoch 4/100\n",
      "136/136 [==============================] - 64s 471ms/step - loss: 0.3385 - f1_score_1: 0.8786 - val_loss: 0.3753 - val_f1_score_1: 0.8804\n",
      "Epoch 5/100\n",
      "136/136 [==============================] - 64s 473ms/step - loss: 0.2721 - f1_score_1: 0.8979 - val_loss: 0.3480 - val_f1_score_1: 0.8918\n",
      "Epoch 6/100\n",
      "136/136 [==============================] - 64s 471ms/step - loss: 0.2223 - f1_score_1: 0.9108 - val_loss: 0.3445 - val_f1_score_1: 0.8892\n",
      "Epoch 7/100\n",
      "136/136 [==============================] - 64s 473ms/step - loss: 0.1833 - f1_score_1: 0.9240 - val_loss: 0.3633 - val_f1_score_1: 0.8980\n",
      "Epoch 8/100\n",
      "136/136 [==============================] - 64s 472ms/step - loss: 0.1499 - f1_score_1: 0.9344 - val_loss: 0.3761 - val_f1_score_1: 0.9027\n",
      "Epoch 9/100\n",
      "136/136 [==============================] - 64s 472ms/step - loss: 0.1236 - f1_score_1: 0.9440 - val_loss: 0.3781 - val_f1_score_1: 0.8995\n",
      "Epoch 10/100\n",
      "136/136 [==============================] - 64s 472ms/step - loss: 0.0986 - f1_score_1: 0.9542 - val_loss: 0.3830 - val_f1_score_1: 0.9018\n"
     ]
    }
   ],
   "source": [
    "history = textRCNN.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_freq=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCNN的f1-score最高达到了0.90, 超过了fastText, 使用该模型提交测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = df_test.text.values.tolist()\n",
    "test_generator = DataGenerator(test_text,\n",
    "                                batch_size=batch_size,\n",
    "                                maxlen=maxlen,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = textRCNN.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(result, axis=1)\n",
    "result = pd.DataFrame({'label': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('rcnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./data/test_a_sample_submit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "base_line.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
